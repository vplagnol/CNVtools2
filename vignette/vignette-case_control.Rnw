%\VignetteIndexEntry{Copy Number Variation Tools}
%\VignetteDepends{CNVtools}
%\VignettePackage{CNVtools}

\documentclass[10pt]{article}
\usepackage{amsmath, amsfonts, amssymb, amsthm}
\usepackage{graphicx}
\usepackage[margin=2cm]{geometry}


\title{CNVtools}
\author{Vincent Plagnol and Chris Barnes}
\date{\today}

\begin{document}
\maketitle

\tableofcontents



\section{What \texttt{CNVtools} is meant to do}


\subsection{Input data}
\texttt{CNVtools} is a \texttt{R} package meant to perform robust case-control and quantitative trait association testing of copy number variants (CNVs).
The association testing procedure for \texttt{CNVtools} requires a one-dimensional normalized data summary per sample. 
Another vector is required to provide the case-control status or, alternatively, a quantitative trait.
Another optional input vector is used to separate the samples in batches in situations where one expects the signal distribution to differentially affect each batch because of potential technical artifacts.
This issue of differential bias is discussed in details in the companion publication published in Nature Genetics in 2008 (see Reference at the end of this vignette).

In addition, \texttt{CNVtools} fits a mixture model to the one-dimensional CNV data summary.
For this approach to make sense, it is essential that the distinct components can at least be distinguished in the histogram of the normalized signal.
If this is not the case mixture models are not an modeling appropriate tool and \texttt{CNVtools} cannot be used to analyze such data.

Note that no code is provided in this package for CNV signal normalization.
However, is it frequent for multiple CNV probes located in the same chromosome region to provide information about the same CNV. 
It is therefore useful to combine the information across a small number of CNV probes to obtain a one-dimensional signal for each sample.
In fact, this summary step is required to use the \texttt{CNVtools} routines which need a one-dimensional data summary as input.
This data summary step is the purpose of the functions \texttt{apply.pca} and \texttt{apply.ldf} which suggest two methods to summarize CNV data across multiple probes: principal component and canonical correlation analysis.
Unlike the actual association testing routines (like \texttt{CNVtest.binary}) and the underlying C code, these two functions are not essential to \texttt{CNVtools} but we thought it would be convenient to include them.


\subsection{Genome-wide or single CNV data}  
Unlike a \texttt{R} package like ``snpMatrix'' specifically designed for genome-wide data, the \texttt{CNVtools} functions are implemented to analyze each CNV separately.
To be more explicit, we did not design data structure to store and analyze data from multiple CNVs (for example genome-wide). 
However, this package was initially designed to analyze CNV data generated by the Wellcome Trust Case Control Consortium, which performed a genome-wide scan for association for eight common disorders (approximately 19,000 samples).
Therefore \texttt{CNVtools} is well suited for large scale CNV association studies but it is the user\'s task to write a wrapper in order to apply the \texttt{CNVtools} code separately for each CNV.
To give some explicit computation time: for the WTCCC CNV association study, and using recently purchased computers (as of 2009, a mixture of Dual-Core AMD Opteron Processor 2220 and Quad-Core AMD Opteron Processor 2384), \texttt{CNVtools} could analyze approximately 3,000 CNVs typed in 19,000 individuals for an approximate total time of 20 days of computing (6h using a 80 nodes computing cluster).



\section{Some very basic association testing}

\subsection{Without a stratification variable}

The first check one can do is that when the CNV calls are very obvious (very clearly separated clusters) the output of the \texttt{CNVtools} association test is consistent with a simple logistic regression.

<<dummy>>=
library(CNVtools) 
#library(survival); source("CNVtools.r"); dyn.load("../src/CNVtools.so"); load("../../CNVtools/data/A112.RData")

set.seed(10)
n <- 1000
CNV <- rbinom(size = 2, n = 1000, prob = 0.3)

beta <- log(1.3)
case.control <- rbinom(prob = -0.3 + exp(beta*CNV)/(1 +  exp(beta*CNV) ), n = n, size = 1)                       
signal <- rnorm(n = n, mean = CNV, sd = 0.05)

test <- new('CNVtools', 
            signal = signal, 
            model.association.H0 = formula(' ~ 1'),
            model.association.H1 = formula(' ~ cn'),
            trait = case.control)

test <- fit(test, ncomp = 3, hyp = 'H0', EM.starting.point = 'kmeans')
test <- fit(test, ncomp = 3, hyp = 'H1')
stat.CNVtools <- 2*(test@mle.H1$lnL - test@mle.H0$lnL)
@ 

We can now compare with the output of the GLM function:
<<glm>>=
mod0 <- glm ( case.control ~ 1, family = binomial)
mod1 <- glm ( case.control ~ CNV, family = binomial)
stat.glm <- diff(anova(mod1, mod0)[[2]])

cat("Comparing both GLM and CNVtools statistics. 
They should be identical: ", stat.CNVtools, ' ', stat.glm, "\n")
@ 

\subsection{Dealing with a discrete covariate}
Now we can redo this check but add a stratification variable to the logistic test.
Again the output of the GLM function should match the test statistic computed from \texttt{CNVtools}.

<<strata>>= 
n <- 1000
beta <- log(2)
association.test.strata <- rbinom( n = n, size = 1, prob = 0.6)
CNV <- rbinom(size = 2, n = 1000, prob = 0.3)
case.control <- rbinom(prob = -0.15 - association.test.strata*0.15 + exp(beta*CNV)/(1 +  exp(beta*CNV) ), n = n, size = 1)
signal <- rnorm(n = n, mean = CNV, sd = 0.05)
my.covar <- data.frame(cc = case.control, region = factor(association.test.strata), cn = CNV)

test.with.strata <- new('CNVtools', signal = signal, 
                        trait = case.control,
                        model.association.H0 = formula(' ~ factor(region)'),
                        model.association.H1 = formula(' ~ factor(region) + cn'),
                        covariates = my.covar)

test.with.strata <- fit(test.with.strata, ncomp = 3, hyp = 'H0', EM.starting.point = 'kmeans')
test.with.strata <- fit(test.with.strata, ncomp = 3, hyp = 'H1', EM.starting.point = 'H1.from.H0')
stat.CNVtools.strata <- 2*(test.with.strata@mle.H1$lnL - test.with.strata@mle.H0$lnL)
@ 


We can now compare with the output of the GLM function:

<<glm>>=
mod0 <- glm ( case.control ~ factor(association.test.strata) , family = binomial)
mod1 <- glm ( case.control ~ factor(association.test.strata) + CNV, family = binomial)
stat.glm <- diff(anova(mod1, mod0)[[2]])

cat("Comparing the statistics again. 
They should again be identical: ", stat.CNVtools.strata, ' ', stat.glm, "\n")
@ 



\section{Analyzing multivariate data}

We first load an example CNV data set, called A112, in the two WTCCC control groups (1958 British Birth cohort and National Blood Services). 
The data required for CNVtools is a matrix of normalized signal intensities. In this example each row represents an individual and each column represents a locus within the CNV. 
To get a feel for the data, we plot the histograms for the mean intensity as well as the first principal component analysis.


<<load.data>>=
data(A112)
raw.signal <- as.matrix(A112[, -c(1,2)])
dimnames(raw.signal)[[1]] <- A112$subject

test <- CNVtools.multivariate.signal(multivariate.signal = raw.signal, 
                                     model.association.H0 = formula(' ~ 1'),
                                     model.association.H1 = formula(' ~ cn'),
                                     batch = A112$cohort,
                                     trait =  (A112$cohort == '58C') )
mean.signal <- test@signal
test <- apply.pca(test)
pca.signal <- test@signal
@ 

<<fig=TRUE, width = 8, height = 5>>=
par(mfrow=c(1,2))
hist(mean.signal, breaks=50, main='Mean signal', cex.lab=1.3, col = 'red')
hist(pca.signal, breaks=50, main='First PCA signal', cex.lab=1.3, col = 'red')  
@ 

\section{Clustering the PCA transformed data}

We can then cluster the result of the pca analysis under the null hypothesis of no association between the number of copies and the case-control status.
The data will be clustered only once, assuming the null hypothesis $\mathbb{H}_0$. Because of this we do not have to specify any case-control status.
We assume free model for the means and the variances for each number of copies using '$\sim$  strata(cn)'.
We could have chosen free variances for each combination of batch and copy number using '$\sim$ strata(cn, batch)'.
Alternatively a variance model proportional to the number of copies is possible using '$\sim$ cn'.
Note, however, that the formulation using strata is much quicker and numerically robust, and should be used when possible. 
We can also provide an optional vector of starting values for the mean locations of the three clusters.

Note that we must check the status of the fit. Only 'C' should be accepted for further analysis. The possibilities include
\begin{itemize}
\item['C'] Converged. This is the only acceptable status.
\item['M'] Maximum iterations reached. The EM algorithm did not converge.
\item['P'] Posterior density problem. The posterior probabilities are not monotonic.
\item['F'] Fit failed. Most likely due to singularity at $\sigma = 0$.
\end{itemize}  
The output contains a list, and the first element of this list is the data frame of interest. 
In the next Figure we plot the result of the clustering.

<<cluster.pca>>=
test <- fit ( test, ncomp = 3, hyp = 'H0')
test <- fit ( test, ncomp = 3, hyp = 'H1')
cat('Convergence: ', test@mle.H0$convergence, ' ', test@mle.H1$convergence)
@ 

Now we can plot the result:
<<fig1, include = false, fig = true, width = 8, height = 5>>=
par(mfrow=c(1,2))
plot.cnv(test, 
         subset = (test@covariates$batch == '58C'),
         main = 'Cohort 58C', 
         breaks = 50, 
         col = 'red',
         xlab = 'PCA')

plot.cnv(test, 
         subset = (test@covariates$batch == 'NBS'),
         main = 'Cohort NBS',
         breaks = 50, 
         col = 'red',
         xlab = 'PCA')
@ 



\begin{figure}[!htb]
  \begin{center}
    \includegraphics[width=11cm]{vignette-case_control-fig1.pdf}
  \end{center}
  \caption{Output of the clustering procedure using the pca (under the null hypothesis $\mathbb{H}_0$ of no allele frequency difference between both cohorts).
  The colored lines show the posterior probability for each of the three copy number classes (copy number $= 1,2$ or $3$).
  For clarity the scale for the posterior probabilities is not shown but the maximum is 1 and the three posterior probabilities always add up to 1.}
  \label{pca-fit.fig}
\end{figure}


\end{document}



